{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "forward-functionality",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the scanning\n",
    "from skimage.filters import threshold_local\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "import os \n",
    "\n",
    "#for the cnn\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "gross-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions linked to scanning\n",
    "\n",
    "def order_points(pts):\n",
    "\t# initialzie a list of coordinates that will be ordered\n",
    "\t# such that the first entry in the list is the top-left,\n",
    "\t# the second entry is the top-right, the third is the\n",
    "\t# bottom-right, and the fourth is the bottom-left\n",
    "\trect = np.zeros((4, 2), dtype = \"float32\")\n",
    "\n",
    "\t# the top-left point will have the smallest sum, whereas\n",
    "\t# the bottom-right point will have the largest sum\n",
    "\ts = pts.sum(axis = 1)\n",
    "\trect[0] = pts[np.argmin(s)]\n",
    "\trect[2] = pts[np.argmax(s)]\n",
    "\n",
    "\t# now, compute the difference between the points, the\n",
    "\t# top-right point will have the smallest difference,\n",
    "\t# whereas the bottom-left will have the largest difference\n",
    "\tdiff = np.diff(pts, axis = 1)\n",
    "\trect[1] = pts[np.argmin(diff)]\n",
    "\trect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "\t# return the ordered coordinates\n",
    "\treturn rect\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "\t# obtain a consistent order of the points and unpack them\n",
    "\t# individually\n",
    "\trect = order_points(pts)\n",
    "\t(tl, tr, br, bl) = rect\n",
    "\n",
    "\t# compute the width of the new image, which will be the\n",
    "\t# maximum distance between bottom-right and bottom-left\n",
    "\t# x-coordiates or the top-right and top-left x-coordinates\n",
    "\twidthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "\twidthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "\tmaxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "\t# compute the height of the new image, which will be the\n",
    "\t# maximum distance between the top-right and bottom-right\n",
    "\t# y-coordinates or the top-left and bottom-left y-coordinates\n",
    "\theightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "\theightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "\tmaxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "\t# now that we have the dimensions of the new image, construct\n",
    "\t# the set of destination points to obtain a \"birds eye view\",\n",
    "\t# (i.e. top-down view) of the image, again specifying points\n",
    "\t# in the top-left, top-right, bottom-right, and bottom-left\n",
    "\t# order\n",
    "\tdst = np.array([\n",
    "\t\t[0, 0],\n",
    "\t\t[maxWidth - 1, 0],\n",
    "\t\t[maxWidth - 1, maxHeight - 1],\n",
    "\t\t[0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "\t# compute the perspective transform matrix and then apply it\n",
    "\tM = cv2.getPerspectiveTransform(rect, dst)\n",
    "\twarped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "\t# return the warped image\n",
    "\treturn warped\n",
    "\n",
    "def findLargestCountours(cntList, cntWidths):\n",
    "    newCntList = []\n",
    "    newCntWidths = []\n",
    "\n",
    "    # finding 1st largest rectangle\n",
    "    first_largest_cnt_pos = cntWidths.index(max(cntWidths))\n",
    "\n",
    "    # adding it in new\n",
    "    newCntList.append(cntList[first_largest_cnt_pos])\n",
    "    newCntWidths.append(cntWidths[first_largest_cnt_pos])\n",
    "\n",
    "    # removing it from old\n",
    "    cntList.pop(first_largest_cnt_pos)\n",
    "    cntWidths.pop(first_largest_cnt_pos)\n",
    "\n",
    "    return newCntList, newCntWidths\n",
    "\n",
    "\n",
    "def scan(image):\n",
    "    ratio = image.shape[0] / 500.0\n",
    "    orig = image.copy()\n",
    "    image = imutils.resize(image, height = 500)\n",
    "\n",
    "    \n",
    "    # convert the image to grayscale, blur it, and find edges\n",
    "    # in the image\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edged = cv2.Canny(gray, 75, 200)\n",
    "   \n",
    "\n",
    "    # find the contours in the edged image, keeping only the\n",
    "    # largest ones, and initialize the screen contour\n",
    "    cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    cnts = sorted(cnts, key = cv2.contourArea, reverse = True)\n",
    "\n",
    "    screenCntList = []\n",
    "    scrWidths = []\n",
    "    \n",
    "    # loop over the contours\n",
    "    for c in cnts:\n",
    "        # approximate the contour\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "        screenCnt = approx\n",
    "\n",
    "        # look at all contour with 4 edges and add them all in a list\n",
    "        if len(screenCnt) == 4:\n",
    "            (X, Y, W, H) = cv2.boundingRect(c)\n",
    "            screenCntList.append(screenCnt)\n",
    "            scrWidths.append(W)\n",
    "    \n",
    "    if not len(screenCntList) >= 1:  # there is no rectangle found\n",
    "        print(\"No rectangle detected in the photo\")\n",
    "    \n",
    "    \n",
    "    for cnt in screenCntList:\n",
    "        image = cv2.drawContours(image, [cnt], -1, (0, 255, 0), 2)\n",
    "    \n",
    "    \n",
    "    #find the largest countour\n",
    "    screenCntBiggest, scrWidthsBiggest = findLargestCountours(screenCntList, scrWidths)\n",
    "    \n",
    "    \n",
    "    # apply the four point transform to obtain a top-down\n",
    "    # view of the original image\n",
    "    warped = four_point_transform(orig, screenCntBiggest[0].reshape(4, 2) * ratio)\n",
    "\n",
    "    #check if it is a LUS image\n",
    "    IMAGE_WIDTH=254\n",
    "    IMAGE_HEIGHT=254\n",
    "    IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "    #result,prediction = is_LUS_image(warped, IMAGE_SIZE)\n",
    "    #print(result)\n",
    "    #print(prediction)\n",
    "    \n",
    "    LUS_image = True\n",
    "    result = True\n",
    "    \n",
    "    while not result:\n",
    "        screenCntBiggest, scrWidthsBiggest = findLargestCountours(screenCntList, scrWidths)  #look for the 2nd biggest rectangle\n",
    "        warped = four_point_transform(orig, screenCntBiggest[0].reshape(4, 2) * ratio)\n",
    "        result,prediction = is_LUS_image(warped, IMAGE_SIZE)\n",
    "        \n",
    "        if not screenCntList:  #check if list is empty\n",
    "            print(\"No LUS image detected\")\n",
    "            LUS_image = False #don't return the scan image but a False boolean\n",
    "            break\n",
    "    \n",
    "    return warped, LUS_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "naughty-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions linked to CNN\n",
    "\n",
    "def is_LUS_image(image, IMAGE_SIZE):\n",
    "    # load model\n",
    "    model = load_model('/LUS_CNN/model.h5')\n",
    "    image = adapt_image_for_cnn(image, IMAGE_SIZE)\n",
    "    predictions = model.predict(image)\n",
    "    predictions = predictions[0]\n",
    "    predictions = round(predictions[0],4)\n",
    "    if predictions < 0.3: \n",
    "        predicted_label='YES.  /'+ '  Score = '+ str(predictions)\n",
    "        result = True\n",
    "    else: \n",
    "        predicted_label='NO   /'+ '  Score = ' + str(predictions)\n",
    "        result = False \n",
    "        \n",
    "    return result, predicted_label\n",
    "\n",
    "\n",
    "def adapt_image_for_cnn(img, IMAGE_SIZE):\n",
    "    img = cv2.resize(img, IMAGE_SIZE)\n",
    "    img_tensor = img_to_array(img)                    # (height, width, channels)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
    "    return img_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "democratic-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to be modified\n",
    "directory_scan = 'DIRECTORY OF IMAGE DATASET YOU WANT TO SCAN'\n",
    "\n",
    "for filename in os.listdir(directory_scan):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        image = cv2.imread(os.path.join(directory_scan ,filename))\n",
    "       \n",
    "        scanned, LUS_image = scan(image)\n",
    "        \n",
    "        if LUS_image:\n",
    "            #to be modified\n",
    "            path = 'PATH WHERE YOU WANT TO STORE THE SCANNED IMAGES'\n",
    "            cv2.imwrite(os.path.join(path ,filename), scanned)\n",
    "    else:\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-biology",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37env",
   "language": "python",
   "name": "python37env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
